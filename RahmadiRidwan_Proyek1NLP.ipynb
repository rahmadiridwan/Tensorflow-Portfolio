{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RahmadiRidwan_Proyek1NLP.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYIz1k-Ki3vA"
      },
      "source": [
        "# RAHMADI RIDWAN\n",
        "# ridwan@blast.co.id\n",
        "\n",
        "import numpy as np\n",
        "import csv"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuRmlcRO71ps"
      },
      "source": [
        "# Dataset yang digunakan adalah dataset berita BBC News yang terdiri atas 2225 baris data"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQ0batysi4zM",
        "outputId": "dd1dcc1d-d825-42ae-e549-6c4d516432a0"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv \\\n",
        "    -O /tmp/bbc-text.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-22 11:36:51--  https://storage.googleapis.com/dataset-uploader/bbc/bbc-text.csv\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.117.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.117.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5057493 (4.8M) [text/csv]\n",
            "Saving to: ‘/tmp/bbc-text.csv’\n",
            "\n",
            "\r/tmp/bbc-text.csv     0%[                    ]       0  --.-KB/s               \r/tmp/bbc-text.csv   100%[===================>]   4.82M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-07-22 11:36:51 (211 MB/s) - ‘/tmp/bbc-text.csv’ saved [5057493/5057493]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAf76bH1i_4b",
        "outputId": "f81db5f9-70bc-482e-88d2-adaa6c7243b9"
      },
      "source": [
        "# import library untuk preprocessing teks\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "inggris = set(stopwords.words('english'))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPwwXb-hjP6-"
      },
      "source": [
        "# Penghilangan stopwords dari dataset dan penampungan isi atribut teks dataset kedalam list articles \n",
        "# dan isi atribut kategori/topik berita list labels (setelah dilucuti stopwordsnya)\n",
        "\n",
        "kelas = []\n",
        "teks = []\n",
        "\n",
        "with open(\"/tmp/bbc-text.csv\", 'r') as csvfile:\n",
        "    reader = csv.reader(csvfile, delimiter=',')\n",
        "    next(reader)\n",
        "    for row in reader:\n",
        "        kelas.append(row[0])\n",
        "        t = row[1]\n",
        "        for word in inggris:\n",
        "            token = ' ' + word + ' '\n",
        "            t = t.replace(token, ' ')\n",
        "            t = t.replace(' ', ' ')\n",
        "        teks.append(t)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MVdGY6i5do9"
      },
      "source": [
        "# pembagian dataset menjadi data training dan data uji\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "teks_training, teks_uji, kelas_training, kelas_uji = train_test_split(teks, kelas, test_size=0.2)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPgY4iM7lKKB"
      },
      "source": [
        "# memuatkan semua dependensi dan library tensorflow dan keras yang dibutuhkan\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Activation, Embedding, Bidirectional"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW069JeujXMV"
      },
      "source": [
        "# tokenisasi teks training\n",
        "\n",
        "tokenizer = Tokenizer(num_words = 5000, oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(teks_training)\n",
        "word_index = tokenizer.word_index"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "da-yQsiBjcfT"
      },
      "source": [
        "# sequencing untuk teks\n",
        "train_sequences = tokenizer.texts_to_sequences(teks_training)\n",
        "validation_sequences = tokenizer.texts_to_sequences(teks_uji)\n",
        "\n",
        "# padding untuk teks\n",
        "train_padded = pad_sequences(train_sequences, maxlen=200, padding='post', truncating='post')\n",
        "validation_padded = pad_sequences(validation_sequences, maxlen=200, padding='post', truncating='post')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qFxfEw1jntD"
      },
      "source": [
        "# tokenisasi kelas/label\n",
        "label_tokenizer = Tokenizer()\n",
        "label_tokenizer.fit_on_texts(kelas)\n",
        "\n",
        "# sequencing untuk kelas/label\n",
        "training_label_seq = np.array(label_tokenizer.texts_to_sequences(kelas_training))\n",
        "validation_label_seq = np.array(label_tokenizer.texts_to_sequences(kelas_uji))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVzw4u4KjsjA"
      },
      "source": [
        "# penyusunan model sequential\n",
        "model = tf.keras.Sequential([tf.keras.layers.Embedding(5000, 64),tf.keras.layers.Dropout(0.5),tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),tf.keras.layers.Dense(6, activation='softmax')])\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF6nQ4zukFks"
      },
      "source": [
        "# kompilasi model dengan parameter optimasi\n",
        "optimasi = tf.keras.optimizers.Adam(learning_rate=0.001, decay=1e-6)\n",
        "model.compile(loss='sparse_categorical_crossentropy',optimizer=optimasi,metrics=['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "scNSy-r9kMcy",
        "outputId": "ce2f0c86-282c-4375-ee3f-fc1ef9026c89"
      },
      "source": [
        "# pelatihan model\n",
        "la_histoire = model.fit(train_padded, training_label_seq, epochs=12, validation_data=(validation_padded, validation_label_seq), verbose=2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "56/56 - 15s - loss: 1.5887 - accuracy: 0.2764 - val_loss: 1.3939 - val_accuracy: 0.3955\n",
            "Epoch 2/12\n",
            "56/56 - 11s - loss: 1.2418 - accuracy: 0.4792 - val_loss: 1.3301 - val_accuracy: 0.6135\n",
            "Epoch 3/12\n",
            "56/56 - 11s - loss: 0.8163 - accuracy: 0.7421 - val_loss: 0.5926 - val_accuracy: 0.8270\n",
            "Epoch 4/12\n",
            "56/56 - 11s - loss: 0.3008 - accuracy: 0.9079 - val_loss: 0.2580 - val_accuracy: 0.9281\n",
            "Epoch 5/12\n",
            "56/56 - 11s - loss: 0.2349 - accuracy: 0.9343 - val_loss: 0.3481 - val_accuracy: 0.9056\n",
            "Epoch 6/12\n",
            "56/56 - 11s - loss: 0.5563 - accuracy: 0.8511 - val_loss: 0.4208 - val_accuracy: 0.8944\n",
            "Epoch 7/12\n",
            "56/56 - 11s - loss: 0.2099 - accuracy: 0.9635 - val_loss: 0.3061 - val_accuracy: 0.9326\n",
            "Epoch 8/12\n",
            "56/56 - 11s - loss: 0.0949 - accuracy: 0.9882 - val_loss: 0.2069 - val_accuracy: 0.9371\n",
            "Epoch 9/12\n",
            "56/56 - 11s - loss: 0.0462 - accuracy: 0.9927 - val_loss: 0.1575 - val_accuracy: 0.9596\n",
            "Epoch 10/12\n",
            "56/56 - 11s - loss: 0.0236 - accuracy: 0.9989 - val_loss: 0.1440 - val_accuracy: 0.9596\n",
            "Epoch 11/12\n",
            "56/56 - 11s - loss: 0.0169 - accuracy: 0.9989 - val_loss: 0.1545 - val_accuracy: 0.9573\n",
            "Epoch 12/12\n",
            "56/56 - 11s - loss: 0.0155 - accuracy: 0.9983 - val_loss: 0.1566 - val_accuracy: 0.9528\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}